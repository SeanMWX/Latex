\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Lecture 1: Introduction, Version spaces}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Some ML examples in practice}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Machine Learning}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Machine Learning learning landscape}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Some basic concepts and terminology}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Input formats (predictive learning)}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Output formats, methods (predictive learning)}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Lecture 2: Induction of decision tree}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview of DT}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Learn trees from data}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Choosing the best test}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Stop splitting nodes}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}A generic algorithm}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Algorithm for "Top-down in duction of decision trees"}}{10}{}\protected@file@percent }
\newlabel{fig:tdidt_algorithm}{{1}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Computational complexity}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Missing values}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Model trees}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Multi-target trees}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10}Practical software}{14}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Lecture 3: Learning sets of rules}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Linear regression}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Trees vs. linear regression vs. inductive bias}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Rule learning}{16}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Algorithm for "General algorithm for rule learning"}}{17}{}\protected@file@percent }
\newlabel{fig:rulesets_algorithm}{{2}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Algorithm for "General algorithm for learning one rule"}}{17}{}\protected@file@percent }
\newlabel{fig:learnonerule_algorithm}{{3}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Association rules}{18}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Differences with Classification and association rules}}{18}{}\protected@file@percent }
\newlabel{tab:diff_classification_association_rules}{{1}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Lecture 4: Instance-based learning, Clustering}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Instance-based learning}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Clustering}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Algorithm for "Algorithm for flat, extensional clustering: K-means"}}{23}{}\protected@file@percent }
\newlabel{fig:kmeans_algorithm}{{4}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Algorithm for "Scheme of Predicttive Cluster"}}{25}{}\protected@file@percent }
\newlabel{fig:scheme_predictive_cluster}{{5}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Lecture 5: Evaluating hypotheses}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Models and learning algorithms}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Statistics}{27}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Alpha for Confidence interval}}{27}{}\protected@file@percent }
\newlabel{tab:diff_classification_association_rules}{{2}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Table for McNemar\'s test}}{29}{}\protected@file@percent }
\newlabel{tab:mcnemar_table}{{3}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Real class vs. predicted class}}{29}{}\protected@file@percent }
\newlabel{tab:real_predicted_class_table}{{4}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Lecture 6: Numerical approaches (ANN, SVM), Computational learning theory}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Lecture 7: Probabilistic approaches, Ensembles}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Lecture 8: Reinforcement learning}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Lecture 9-10: Inductive logic programming}{30}{}\protected@file@percent }
\gdef \@abspage@last{32}
